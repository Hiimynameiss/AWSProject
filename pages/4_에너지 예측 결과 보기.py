import streamlit as st
import pandas as pd
import os
import json
# import requests # Not used in the provided snippet for SageMaker invocation
import boto3
from datetime import datetime, timedelta
import plotly.graph_objects as go
import numpy as np

# AWS SageMaker Runtime Client
# Ensure your AWS credentials and region are configured (e.g., via environment variables, ~/.aws/credentials)
try:
    #client = boto3.client("sagemaker-runtime", ) # Removed region_name to allow boto3 to determine it from config
    client = boto3.client("sagemaker-runtime", region_name="ap-northeast-2")  # ì˜ˆ: ì„œìš¸ ë¦¬ì „
except Exception as e:
    st.error(f"AWS Boto3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. AWS ì„¤ì •(ìê²© ì¦ëª…, ë¦¬ì „)ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

st.title("ğŸ” ì „ë ¥ ì†Œë¹„ëŸ‰ ì˜ˆì¸¡ ë° ë¶„ì„")

# --- Configuration ---
SAGEMAKER_ENDPOINT_NAME = "tft-endpoint"  # S ì‹¤ì œ SageMaker ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!
ELECTRICITY_RATE_KWH = 180  # ì›/kWh
CARBON_COEFFICIENT_KWH = 0.424  # kgCO2/kWh
TARGET_COLUMN = 'hourly_pow' # ì˜ˆì¸¡ ëŒ€ìƒ ì»¬ëŸ¼ (ê²€ì¦ìš© ë°ì´í„° ì…‹ì˜ ì¼ë¶€.txt ê¸°ë°˜ [cite: 2])
TIME_COLUMN = 'id'           # ì‹œê°„ ì»¬ëŸ¼ (ê²€ì¦ìš© ë°ì´í„° ì…‹ì˜ ì¼ë¶€.txt ê¸°ë°˜ [cite: 2])

# ì¶”ë¡  ìš”ì²­ í•¨ìˆ˜
def invoke_sagemaker_endpoint(endpoint_name, payload_data):
    try:
        response = client.invoke_endpoint(
            EndpointName=endpoint_name,
            ContentType="application/json",
            Body=json.dumps(payload_data)
        )
        return json.loads(response["Body"].read().decode("utf-8"))
    except Exception as e:
        st.error(f"SageMaker ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ì—…ë¡œë“œëœ íŒŒì¼ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
def save_uploaded_file(directory, file):
    if not os.path.exists(directory):
        os.makedirs(directory)
    file_path = os.path.join(directory, file.name)
    with open(file_path, 'wb') as f:
        f.write(file.getbuffer())
    return file_path

# ------------------------

# ğŸ” ì´ì „ í˜ì´ì§€ì—ì„œ ì—…ë¡œë“œí•œ íŒŒì¼ ê²½ë¡œ ì‚¬ìš© ë˜ëŠ” ì§ì ‘ ì—…ë¡œë“œ
# st.session_stateì—ì„œ file_pathë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜, ì´ í˜ì´ì§€ì—ì„œ ì§ì ‘ ì—…ë¡œë“œí•˜ë„ë¡ ìˆ˜ì •
uploaded_file_path_from_session = st.session_state.get('uploaded_file_path', None)
uploaded_file_direct = st.file_uploader("ì˜ˆì¸¡ì„ ìœ„í•œ CSV íŒŒì¼ ì—…ë¡œë“œ (ì„¸ì…˜ì— íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)", type=['csv'])

# Google Drive ê³µìœ  ë§í¬ë¥¼ í†µí•œ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
st.markdown("ë˜ëŠ” ğŸ‘‰ **Google Drive ê³µìœ  ë§í¬ ì…ë ¥**")
google_drive_url = st.text_input("ğŸ”— Google Drive ê³µìœ  CSV íŒŒì¼ URL", placeholder="https://drive.google.com/file/d/18r04ZNRd_Fz58Ay_g-7uY-6XK5q_P6V6/view?usp=sharing")

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê³µìœ  ë§í¬ë¥¼ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ë§í¬ë¡œ ë³€í™˜
def extract_google_drive_file_id(url):
    if "drive.google.com" in url:
        if "/file/d/" in url:
            return url.split("/file/d/")[1].split("/")[0]
        elif "id=" in url:
            return url.split("id=")[1]
    return None

def get_direct_download_url(file_id):
    return f"https://drive.google.com/uc?export=download&id={file_id}"

file_to_process = None
if google_drive_url:
    file_id = extract_google_drive_file_id(google_drive_url)
    if file_id:
        direct_url = get_direct_download_url(file_id)
        try:
            df_input_data = pd.read_csv(direct_url)
            st.success("âœ… Google Drive íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âŒ Google Driveì—ì„œ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            st.stop()
    else:
        st.warning("âš ï¸ ìœ íš¨í•œ Google Drive ê³µìœ  ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


file_to_process = None
temp_file_path = None # ì§ì ‘ ì—…ë¡œë“œ ì‹œ ì„ì‹œ ì €ì¥ ê²½ë¡œ

if uploaded_file_direct:
    # ì‚¬ìš©ìê°€ ì´ í˜ì´ì§€ì—ì„œ ì§ì ‘ íŒŒì¼ì„ ì—…ë¡œë“œí•œ ê²½ìš°
    current_time_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    direct_uploaded_filename = f"direct_upload_{current_time_str}_{uploaded_file_direct.name}"
    # save_uploaded_file í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ íŒŒì¼ ê°ì²´ì˜ name ì†ì„±ì„ ì„¤ì •
    class UploadedFileWithName:
        def __init__(self, file_obj, name):
            self._file_obj = file_obj
            self.name = name
        def getbuffer(self):
            return self._file_obj.getbuffer()

    file_to_process = UploadedFileWithName(uploaded_file_direct, direct_uploaded_filename)
    temp_file_path = save_uploaded_file("temp_uploads", file_to_process) # ì„ì‹œ ì €ì¥
    st.success(f"âœ… ì§ì ‘ ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš©: `{file_to_process.name}`")
elif uploaded_file_path_from_session:
    # ì„¸ì…˜ ìƒíƒœì—ì„œ íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
    if os.path.exists(uploaded_file_path_from_session):
        file_to_process = uploaded_file_path_from_session
        st.success(f"âœ… ì„¸ì…˜ì—ì„œ ë¶ˆëŸ¬ì˜¨ íŒŒì¼ ì‚¬ìš©: `{os.path.basename(file_to_process)}`")
    else:
        st.warning("ì„¸ì…˜ì˜ íŒŒì¼ ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì§ì ‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()
else:
    st.info("ğŸ“‚ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (ì´ì „ í˜ì´ì§€ ë˜ëŠ” ì—¬ê¸°ì„œ ì§ì ‘)")
    st.stop()

# íŒŒì¼ ì²˜ë¦¬ (ê²½ë¡œ ë˜ëŠ” íŒŒì¼ ê°ì²´)
df_input_data = None
if file_to_process:
    try:
        # file_to_processê°€ ê²½ë¡œ ë¬¸ìì—´ì¸ ê²½ìš°ì™€ íŒŒì¼ ê°ì²´ì¸ ê²½ìš°ë¥¼ ëª¨ë‘ ì²˜ë¦¬
        file_path_for_reading = temp_file_path if temp_file_path else file_to_process

        encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']
        df_temp = None
        for enc in encodings:
            try:
                df_temp = pd.read_csv(file_path_for_reading, encoding=enc)
                break
            except UnicodeDecodeError:
                continue
        
        if df_temp is None:
            st.error("âŒ CSV íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸ì½”ë”© ë¬¸ì œì…ë‹ˆë‹¤.")
            st.stop()
        df_input_data = df_temp

    except Exception as e:
        st.error(f"âŒ CSV íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()
    finally:
        if temp_file_path and os.path.exists(temp_file_path): # ì„ì‹œ íŒŒì¼ ì‚­ì œ
             try:
                os.remove(temp_file_path)
             except Exception:
                pass # ì‚­ì œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

if df_input_data is not None:
    # ë°ì´í„° ì „ì²˜ë¦¬
    if TIME_COLUMN not in df_input_data.columns:
        st.error(f"'{TIME_COLUMN}' ì»¬ëŸ¼ì´ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤. (ì‹œê°„ ì •ë³´ ì»¬ëŸ¼)")
        st.stop()
    if TARGET_COLUMN not in df_input_data.columns:
        st.error(f"'{TARGET_COLUMN}' ì»¬ëŸ¼ì´ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤. (ì˜ˆì¸¡ ëŒ€ìƒ ì»¬ëŸ¼)")
        st.stop()

    try:
        df_input_data[TIME_COLUMN] = pd.to_datetime(df_input_data[TIME_COLUMN])
        df_input_data[TARGET_COLUMN] = pd.to_numeric(df_input_data[TARGET_COLUMN], errors='coerce')
        df_input_data = df_input_data.dropna(subset=[TARGET_COLUMN]) # NaNs in target
        df_input_data = df_input_data.sort_values(by=TIME_COLUMN).reset_index(drop=True)
    except Exception as e:
        st.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì‹œê°„ ë³€í™˜ ë˜ëŠ” ìˆ«ì ë³€í™˜): {e}")
        st.stop()

    st.subheader("ğŸ‘€ ì…ë ¥ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì „ì²˜ë¦¬ í›„)")
    st.dataframe(df_input_data.head())

    # ì˜ˆì¸¡ ê¸°ê°„(horizon) ì„¤ì •
    # ê²€ì¦ìš© ë°ì´í„°ì…‹ì€ ì‹œê°„ë‹¹ í•˜ë‚˜ì˜ ë ˆì½”ë“œë¥¼ ê°€ì§‘ë‹ˆë‹¤. [cite: 2]
    min_horizon = 1
    max_horizon = min(168, len(df_input_data) - 1) # ìµœì†Œ 1ê°œì˜ ë°ì´í„°ëŠ” ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ ë‚¨ê²¨ë‘ 
    
    if max_horizon < min_horizon:
        st.warning(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ {min_horizon + 1}ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()

    horizon = st.number_input("ğŸ“ˆ ì˜ˆì¸¡ ê¸°ê°„ (ì‹œê°„ ë‹¨ìœ„, horizon)", min_value=min_horizon, max_value=max_horizon, value=min(6, max_horizon), step=1)

    # MAE ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„° ë¶„ë¦¬
    actual_df_for_mae = df_input_data.iloc[-horizon:].copy()
    model_input_df = df_input_data.iloc[:-horizon].copy()

    if model_input_df.empty:
        st.error("ëª¨ë¸ì— ì…ë ¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (horizon ì„¤ì •ì´ ë„ˆë¬´ í½ë‹ˆë‹¤). Horizon ê°’ì„ ì¤„ì—¬ì£¼ì„¸ìš”.")
        st.stop()

    st.markdown("---")
    st.subheader("ğŸš€ ì¶”ë¡  ì‹¤í–‰")
    
    # SageMaker í˜ì´ë¡œë“œ êµ¬ì„± (ëª¨ë¸ì˜ ê¸°ëŒ€ í˜•ì‹ì— ë§ê²Œ ì¡°ì • í•„ìš”)
    # ì˜ˆì‹œ: ë‹¨ìˆœíˆ target seriesì™€ horizonì„ ì „ë‹¬
    # ì‹¤ì œ ëª¨ë¸ì´ ë” ë³µì¡í•œ ì…ë ¥ì„ ìš”êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (e.g., start_time, features)
    payload = {
        # ë‹¤ìŒì€ ì¼ë°˜ì ì¸ SageMaker ì‹œê³„ì—´ ëª¨ë¸ì˜ ì…ë ¥ í˜•ì‹ ì˜ˆì‹œì…ë‹ˆë‹¤.
        # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ì˜ ì…ë ¥ í˜•ì‹ì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
        "instances": [
            {
                "start": model_input_df[TIME_COLUMN].iloc[0].strftime("%Y-%m-%d %H:%M:%S"),
                "target": model_input_df[TARGET_COLUMN].tolist(),
                # "dynamic_feat": [[...]], # ë§Œì•½ ì™¸ë¶€ íŠ¹ì§•ì„ ì‚¬ìš©í•œë‹¤ë©´
            }
        ],
        "configuration": {
            "num_samples": 50, # ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜ (í‰ê·  ì˜ˆì¸¡ë§Œ í•„ìš”í•˜ë©´ 1 ë˜ëŠ” ì œê±°)
            "output_types": ["mean"], # "mean", "quantiles", "samples" ë“±
            "quantiles": ["0.1", "0.5", "0.9"] # ë§Œì•½ output_typesì— "quantiles"ê°€ ìˆë‹¤ë©´
        }
    }
    # ìœ„ì˜ í˜ì´ë¡œë“œëŠ” DeepARê³¼ ê°™ì€ SageMaker ë‚´ì¥ ì•Œê³ ë¦¬ì¦˜ì˜ ì¼ë°˜ì ì¸ í˜•íƒœì…ë‹ˆë‹¤.
    # ëª¨ë¸ì´ ë‹¨ìˆœí•œ ë¦¬ìŠ¤íŠ¸ë‚˜ ë‹¤ë¥¸ êµ¬ì¡°ë¥¼ ê¸°ëŒ€í•œë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •:
    # payload = {
    #     "target_series": model_input_df[TARGET_COLUMN].tolist(),
    #     "horizon": horizon
    # }
    # ì‚¬ìš©ìì˜ ëª¨ë¸ì— ë§ê²Œ payloadë¥¼ ì •í™•íˆ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

    if st.button("â˜ï¸ SageMakerë¡œ ì¶”ë¡  ìš”ì²­í•˜ê¸°"):
        if SAGEMAKER_ENDPOINT_NAME == "tft-endpoint":
            st.error("SageMaker ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„ì„ ì„¤ì •í•´ì£¼ì„¸ìš” (SAGEMAKER_ENDPOINT_NAME).")
        else:
            with st.spinner("SageMaker ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì˜ˆì¸¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                sagemaker_result = invoke_sagemaker_endpoint(SAGEMAKER_ENDPOINT_NAME, payload)

            if sagemaker_result:
                st.success("âœ… ì¶”ë¡  ì„±ê³µ")
                st.session_state['sagemaker_result'] = sagemaker_result # ê²°ê³¼ ì €ì¥
                st.session_state['actual_df_for_mae'] = actual_df_for_mae
                st.session_state['model_input_df'] = model_input_df
                st.session_state['horizon'] = horizon
                # ë‹¤ìŒ ì„¹ì…˜ì—ì„œ ê²°ê³¼ë¥¼ í‘œì‹œí•˜ê¸° ìœ„í•´ í˜ì´ì§€ë¥¼ ë‹¤ì‹œ ë¡œë“œí•  í•„ìš”ëŠ” ì—†ìŒ
            else:
                st.error("âŒ ì¶”ë¡  ì‹¤íŒ¨. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    if 'sagemaker_result' in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ“Š ì¶”ë¡  ê²°ê³¼ ë¶„ì„")
        
        sagemaker_result = st.session_state['sagemaker_result']
        actual_df_for_mae = st.session_state['actual_df_for_mae']
        model_input_df = st.session_state['model_input_df']
        horizon = st.session_state['horizon']

        try:
            # SageMaker ê²°ê³¼ íŒŒì‹± (ëª¨ë¸ì˜ ì‘ë‹µ í˜•ì‹ì— ë”°ë¼ í¬ê²Œ ë‹¬ë¼ì§)
            # ì˜ˆì‹œ: ì‘ë‹µì´ {"predictions": [{"mean": [val1, val2, ...]}]} í˜•íƒœì¼ ê²½ìš°
            if isinstance(sagemaker_result, dict) and "predictions" in sagemaker_result:
                if isinstance(sagemaker_result["predictions"], list) and \
                   len(sagemaker_result["predictions"]) > 0 and \
                   isinstance(sagemaker_result["predictions"][0], dict) and \
                   "mean" in sagemaker_result["predictions"][0] and \
                   len(sagemaker_result["predictions"][0]["mean"]) == horizon:
                    
                    predicted_values = sagemaker_result["predictions"][0]["mean"]
                else: # ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ê°€ì •
                    predicted_values = sagemaker_result.get("predictions", []) # ë˜ëŠ” ë‹¤ë¥¸ í‚¤
                    if not isinstance(predicted_values, list) or len(predicted_values) != horizon :
                         st.error(f"SageMaker ì‘ë‹µì—ì„œ 'predictions' í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì˜ˆì¸¡ ê°œìˆ˜({len(predicted_values)})ê°€ horizon({horizon})ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                         st.json(sagemaker_result) # ì‹¤ì œ ì‘ë‹µ êµ¬ì¡° í™•ì¸ìš©
                         st.stop()

            elif isinstance(sagemaker_result, list) and len(sagemaker_result) == horizon: # ì‘ë‹µì´ ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸ ìì²´ì¼ ê²½ìš°
                predicted_values = sagemaker_result
            else: # ì˜ˆì¸¡í•  ìˆ˜ ì—†ëŠ” êµ¬ì¡°
                st.error(f"SageMaker ì‘ë‹µì˜ êµ¬ì¡°ë¥¼ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'predictions' í‚¤ ë˜ëŠ” ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                st.json(sagemaker_result) # ì‹¤ì œ ì‘ë‹µ êµ¬ì¡° í™•ì¸ìš©
                st.stop()

            # ì˜ˆì¸¡ê°’ì— ëŒ€í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
            last_input_time = model_input_df[TIME_COLUMN].iloc[-1]
            # ê²€ì¦ìš© ë°ì´í„°ì…‹ì˜ ì‹œê°„ ê°„ê²©ì€ 1ì‹œê°„ [cite: 2]
            prediction_timestamps = pd.date_range(start=last_input_time + timedelta(hours=1), periods=horizon, freq='H')

            df_predictions = pd.DataFrame({
                TIME_COLUMN: prediction_timestamps,
                f'predicted_{TARGET_COLUMN}': predicted_values
            })

            # 1. ActivePower (hourly_pow) ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
            st.markdown(f"#### 1. {TARGET_COLUMN} ì˜ˆì¸¡ ê²°ê³¼")
            fig_power = go.Figure()
            fig_power.add_trace(go.Scatter(x=df_input_data[TIME_COLUMN], y=df_input_data[TARGET_COLUMN],
                                           mode='lines', name='ì‹¤ì œê°’ (ì „ì²´)', line=dict(color='blue')))
            fig_power.add_trace(go.Scatter(x=df_predictions[TIME_COLUMN], y=df_predictions[f'predicted_{TARGET_COLUMN}'],
                                           mode='lines+markers', name='ì˜ˆì¸¡ê°’', line=dict(color='red')))
            # MAE ê³„ì‚°ì„ ìœ„í•´ ì‚¬ìš©ëœ ì‹¤ì œê°’ë„ í‘œì‹œ
            fig_power.add_trace(go.Scatter(x=actual_df_for_mae[TIME_COLUMN], y=actual_df_for_mae[TARGET_COLUMN],
                                           mode='markers', name='ì‹¤ì œê°’ (MAE ë¹„êµ ëŒ€ìƒ)', marker=dict(color='orange', size=8)))
            
            fig_power.update_layout(title=f'{TARGET_COLUMN} ì‹¤ì œê°’ vs. ì˜ˆì¸¡ê°’',
                                    xaxis_title='ì‹œê°„', yaxis_title='ì „ë ¥ ì†Œë¹„ëŸ‰ (hourly_pow)')
            st.plotly_chart(fig_power, use_container_width=True)

            # 2. ì „ê¸° ìš”ê¸ˆ ë° íƒ„ì†Œ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ ì‹œê°í™”
            st.markdown("#### 2. ì˜ˆì¸¡ëœ ì „ê¸° ìš”ê¸ˆ ë° íƒ„ì†Œ ë°°ì¶œëŸ‰")
            df_predictions['predicted_bill (ì›)'] = df_predictions[f'predicted_{TARGET_COLUMN}'] * ELECTRICITY_RATE_KWH
            df_predictions['predicted_carbon (kgCO2)'] = df_predictions[f'predicted_{TARGET_COLUMN}'] * CARBON_COEFFICIENT_KWH

            fig_derived = go.Figure()
            fig_derived.add_trace(go.Scatter(x=df_predictions[TIME_COLUMN], y=df_predictions['predicted_bill (ì›)'],
                                             mode='lines', name='ì˜ˆìƒ ì „ê¸° ìš”ê¸ˆ (ì›)', yaxis="y1"))
            fig_derived.add_trace(go.Scatter(x=df_predictions[TIME_COLUMN], y=df_predictions['predicted_carbon (kgCO2)'],
                                             mode='lines', name='ì˜ˆìƒ íƒ„ì†Œ ë°°ì¶œëŸ‰ (kgCO2)', yaxis="y2"))

            fig_derived.update_layout(
                title='ì‹œê°„ëŒ€ë³„ ì˜ˆìƒ ì „ê¸° ìš”ê¸ˆ ë° íƒ„ì†Œ ë°°ì¶œëŸ‰',
                xaxis_title='ì‹œê°„',
                yaxis=dict(title='ì˜ˆìƒ ì „ê¸° ìš”ê¸ˆ (ì›)', side='left', showgrid=False),
                yaxis2=dict(title='ì˜ˆìƒ íƒ„ì†Œ ë°°ì¶œëŸ‰ (kgCO2)', side='right', overlaying='y', showgrid=False),
                legend=dict(x=0.1, y=1.1, orientation="h")
            )
            st.plotly_chart(fig_derived, use_container_width=True)
            
            st.dataframe(df_predictions[[TIME_COLUMN, f'predicted_{TARGET_COLUMN}', 'predicted_bill (ì›)', 'predicted_carbon (kgCO2)']].head())

            # 3. MAE ì •í™•ë„ ìˆ˜ì¹˜í™” / ì‹œê°í™”
            st.markdown("#### 3. ëª¨ë¸ ì •í™•ë„ (MAE)")
            # ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ì‹œê°„ ì •ë ¬ ë° ë³‘í•©
            comparison_df = pd.merge(actual_df_for_mae[[TIME_COLUMN, TARGET_COLUMN]],
                                     df_predictions[[TIME_COLUMN, f'predicted_{TARGET_COLUMN}']],
                                     on=TIME_COLUMN, how='inner')
            
            if comparison_df.empty or len(comparison_df) != horizon:
                st.warning(f"MAEë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ë§¤ì¹­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ë§¤ì¹­ëœ í–‰: {len(comparison_df)}, Horizon: {horizon}) íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            else:
                mae = np.mean(np.abs(comparison_df[TARGET_COLUMN] - comparison_df[f'predicted_{TARGET_COLUMN}']))
                st.metric(label=f"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE) for {TARGET_COLUMN}", value=f"{mae:.4f}")

                # MAE ì‹œê°í™” (ê²Œì´ì§€ ì°¨íŠ¸)
                max_mae_gauge = max(mae * 2, np.mean(actual_df_for_mae[TARGET_COLUMN]) * 0.5) # ê²Œì´ì§€ ìµœëŒ€ê°’ ë™ì  ì„¤ì •
                if max_mae_gauge == 0 : max_mae_gauge = 1 # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒ ë°©ì§€

                fig_mae_gauge = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=mae,
                    title={'text': f"MAE ({TARGET_COLUMN})<br><span style='font-size:0.8em;color:gray'>(ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)</span>"},
                    gauge={
                        'axis': {'range': [0, max_mae_gauge]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, max_mae_gauge * 0.25], 'color': "lightgreen"},
                            {'range': [max_mae_gauge * 0.25, max_mae_gauge * 0.5], 'color': "yellow"},
                            {'range': [max_mae_gauge * 0.5, max_mae_gauge], 'color': "lightcoral"}
                        ],
                    }
                ))
                fig_mae_gauge.update_layout(height=300)
                st.plotly_chart(fig_mae_gauge, use_container_width=True)
                
                # ì˜¤ì°¨ ì‹œê°í™” (ì‹¤ì œ vs ì˜ˆì¸¡)
                fig_error = go.Figure()
                fig_error.add_trace(go.Scatter(x=comparison_df[TIME_COLUMN], y=comparison_df[TARGET_COLUMN], mode='lines+markers', name='ì‹¤ì œê°’'))
                fig_error.add_trace(go.Scatter(x=comparison_df[TIME_COLUMN], y=comparison_df[f'predicted_{TARGET_COLUMN}'], mode='lines+markers', name='ì˜ˆì¸¡ê°’'))
                fig_error.update_layout(title='MAE ë¹„êµ: ì‹¤ì œê°’ vs. ì˜ˆì¸¡ê°’ (ì˜ˆì¸¡ ê¸°ê°„)', xaxis_title='ì‹œê°„', yaxis_title=TARGET_COLUMN)
                st.plotly_chart(fig_error, use_container_width=True)


        except Exception as e:
            st.error(f"ê²°ê³¼ ì²˜ë¦¬ ë˜ëŠ” ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.write("SageMaker ì‘ë‹µ ë°ì´í„°:")
            st.json(sagemaker_result) # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‹¤ì œ ì‘ë‹µ ë°ì´í„° ì¶œë ¥

# ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥ (ë‹¤ë¥¸ í˜ì´ì§€ë¡œ ë„˜ê¸¸ ê²½ìš°)
# if 'sagemaker_result' in st.session_state and 'df_predictions' in locals():
# st.session_state["inference_results_for_viz"] = {
# "predictions_df": df_predictions.to_dict(),
# "mae": mae if 'mae' in locals() else None
# }
