import streamlit as st
import pandas as pd
import os
import json
import boto3
from datetime import datetime, timedelta
import plotly.graph_objects as go
import numpy as np

# AWS SageMaker Runtime Client
try:
    client = boto3.client("sagemaker-runtime", region_name="ap-northeast-2")  # ì„œìš¸ ë¦¬ì „
except Exception as e:
    st.error(f"AWS Boto3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. AWS ì„¤ì •(ìê²© ì¦ëª…, ë¦¬ì „)ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

st.title("ğŸ” ì „ë ¥ ì†Œë¹„ëŸ‰ ì˜ˆì¸¡ ë° ë¶„ì„")

# --- Configuration ---
SAGEMAKER_ENDPOINT_NAME = "tft-endpoint"  # ì‹¤ì œ SageMaker ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!
ELECTRICITY_RATE_KWH = 180  # ì›/kWh
CARBON_COEFFICIENT_KWH = 0.424  # kgCO2/kWh
TARGET_COLUMN = 'activePower' # ì˜ˆì¸¡ ëŒ€ìƒ ì»¬ëŸ¼
TIME_COLUMN = 'timestamp'     # ì‹œê°„ ì»¬ëŸ¼ (ê³µë°± ì œê±°)

# ì¶”ë¡  ìš”ì²­ í•¨ìˆ˜
def invoke_sagemaker_endpoint(endpoint_name, payload_data):
    try:
        response = client.invoke_endpoint(
            EndpointName=endpoint_name,
            ContentType="application/json",
            Body=json.dumps(payload_data)
        )
        return json.loads(response["Body"].read().decode("utf-8"))
    except Exception as e:
        st.error(f"SageMaker ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ì—…ë¡œë“œëœ íŒŒì¼ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_uploaded_file(directory, file):
    if not os.path.exists(directory):
        os.makedirs(directory)
    file_path = os.path.join(directory, file.name)
    with open(file_path, 'wb') as f:
        f.write(file.getbuffer())
    return file_path

# Unix timestamp (ë°€ë¦¬ì´ˆ)ë¥¼ datetimeìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_unix_timestamp_ms(timestamp):
    """Unix timestamp (ë°€ë¦¬ì´ˆ)ë¥¼ pandas datetimeìœ¼ë¡œ ë³€í™˜"""
    return pd.to_datetime(timestamp, unit='ms')

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê´€ë ¨ í•¨ìˆ˜ë“¤
def extract_google_drive_file_id(url):
    if "drive.google.com" in url:
        if "/file/d/" in url:
            return url.split("/file/d/")[1].split("/")[0]
        elif "id=" in url:
            return url.split("id=")[1]
    return None

def get_direct_download_url(file_id):
    return f"https://drive.google.com/uc?export=download&id={file_id}"

# íŒŒì¼ ì—…ë¡œë“œ ë° Google Drive ë§í¬ ì…ë ¥
uploaded_file_path_from_session = st.session_state.get('uploaded_file_path', None)
uploaded_file_direct = st.file_uploader("ì˜ˆì¸¡ì„ ìœ„í•œ CSV íŒŒì¼ ì—…ë¡œë“œ", type=['csv'])

st.write("ë˜ëŠ” ğŸ‘‰ **Google Drive ê³µìœ  ë§í¬ ì…ë ¥**")
google_drive_url = st.text_input("ğŸ”— Google Drive ê³µìœ  CSV íŒŒì¼ URL", 
                                placeholder="https://drive.google.com/file/d/.../view?usp=sharing",
                                value="https://drive.google.com/file/d/18r04ZNRd_Fz58Ay_g-7uY-6XK5q_P6V6/view?usp=sharing")

# ë°ì´í„° ë¡œë”©
df_input_data = None

# Google Driveì—ì„œ ë°ì´í„° ë¡œë”©
if google_drive_url:
    file_id = extract_google_drive_file_id(google_drive_url)
    if file_id:
        direct_url = get_direct_download_url(file_id)
        try:
            df_input_data = pd.read_csv(direct_url, header=0)
            df_input_data.columns = df_input_data.columns.str.strip()
            st.success("âœ… Google Drive íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âŒ Google Driveì—ì„œ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            df_input_data = None
    else:
        st.warning("âš ï¸ ìœ íš¨í•œ Google Drive ê³µìœ  ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ì§ì ‘ ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
elif uploaded_file_direct:
    try:
        df_input_data = pd.read_csv(uploaded_file_direct)
        df_input_data.columns = df_input_data.columns.str.strip()
        st.success(f"âœ… ì§ì ‘ ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš©: `{uploaded_file_direct.name}`")
    except Exception as e:
        st.error(f"âŒ ì—…ë¡œë“œëœ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        df_input_data = None

# ì„¸ì…˜ì—ì„œ íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
elif uploaded_file_path_from_session and os.path.exists(uploaded_file_path_from_session):
    try:
        encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']
        df_input_data = None
        for enc in encodings:
            try:
                df_input_data = pd.read_csv(uploaded_file_path_from_session, encoding=enc)
                df_input_data.columns = df_input_data.columns.str.strip()
                break
            except UnicodeDecodeError:
                continue
        
        if df_input_data is not None:
            st.success(f"âœ… ì„¸ì…˜ì—ì„œ ë¶ˆëŸ¬ì˜¨ íŒŒì¼ ì‚¬ìš©: `{os.path.basename(uploaded_file_path_from_session)}`")
        else:
            st.error("âŒ ì„¸ì…˜ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸ì½”ë”© ë¬¸ì œì…ë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"âŒ ì„¸ì…˜ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        df_input_data = None

else:
    st.info("ğŸ“‚ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ Google Drive ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ë°ì´í„°ê°€ ë¡œë”©ëœ ê²½ìš° ì²˜ë¦¬ ì§„í–‰
if df_input_data is not None:
    # ì»¬ëŸ¼ í™•ì¸
    st.write("ğŸ“‹ ë°ì´í„°ì…‹ ì»¬ëŸ¼:", list(df_input_data.columns))
    
    if TIME_COLUMN not in df_input_data.columns:
        st.error(f"'{TIME_COLUMN}' ì»¬ëŸ¼ì´ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df_input_data.columns)}")
        st.stop()
    if TARGET_COLUMN not in df_input_data.columns:
        st.error(f"'{TARGET_COLUMN}' ì»¬ëŸ¼ì´ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df_input_data.columns)}")
        st.stop()

    # ë°ì´í„° ì „ì²˜ë¦¬
    try:
        # Unix timestamp (ë°€ë¦¬ì´ˆ)ë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        df_input_data[TIME_COLUMN] = convert_unix_timestamp_ms(df_input_data[TIME_COLUMN])
        df_input_data[TARGET_COLUMN] = pd.to_numeric(df_input_data[TARGET_COLUMN], errors='coerce')
        df_input_data = df_input_data.dropna(subset=[TARGET_COLUMN])
        df_input_data = df_input_data.sort_values(by=TIME_COLUMN).reset_index(drop=True)
        
        st.success("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.write("íƒ€ì„ìŠ¤íƒ¬í”„ ìƒ˜í”Œ ê°’:", df_input_data[TIME_COLUMN].head())
        st.stop()

    st.subheader("ğŸ‘€ ì…ë ¥ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì „ì²˜ë¦¬ í›„)")
    st.dataframe(df_input_data[[TIME_COLUMN, TARGET_COLUMN]].head(10))

    # ì˜ˆì¸¡ ê¸°ê°„(horizon) ì„¤ì •
    min_horizon = 1
    max_horizon = min(168, len(df_input_data) - 1)
    
    if max_horizon < min_horizon:
        st.warning(f"ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ {min_horizon + 1}ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()

    horizon = st.number_input("ğŸ“ˆ ì˜ˆì¸¡ ê¸°ê°„ (ì‹œê°„ ë‹¨ìœ„, horizon)", 
                             min_value=min_horizon, 
                             max_value=max_horizon, 
                             value=min(6, max_horizon), 
                             step=1)

    # MAE ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„° ë¶„ë¦¬
    actual_df_for_mae = df_input_data.iloc[-horizon:].copy()
    model_input_df = df_input_data.iloc[:-horizon].copy()

    if model_input_df.empty:
        st.error("ëª¨ë¸ì— ì…ë ¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (horizon ì„¤ì •ì´ ë„ˆë¬´ í½ë‹ˆë‹¤). Horizon ê°’ì„ ì¤„ì—¬ì£¼ì„¸ìš”.")
        st.stop()

    st.write("---")
    st.subheader("ğŸš€ ì¶”ë¡  ì‹¤í–‰")
    
    # SageMaker í˜ì´ë¡œë“œ êµ¬ì„±
    payload = {
        "instances": [
            {
                "start": model_input_df[TIME_COLUMN].iloc[0].strftime("%Y-%m-%d %H:%M:%S"),
                "target": model_input_df[TARGET_COLUMN].tolist(),
            }
        ],
        "configuration": {
            "num_samples": 50,
            "output_types": ["mean"],
            "quantiles": ["0.1", "0.5", "0.9"]
        }
    }

    # ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„ ì„¤ì •
    endpoint_name = st.text_input("ğŸ”— SageMaker ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„", 
                                 value=SAGEMAKER_ENDPOINT_NAME,
                                 help="ì‹¤ì œ ë°°í¬ëœ SageMaker ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")

    if st.button("â˜ï¸ SageMakerë¡œ ì¶”ë¡  ìš”ì²­í•˜ê¸°"):
        if endpoint_name == "tft-endpoint":
            st.warning("âš ï¸ ì‹¤ì œ SageMaker ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("SageMaker ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì˜ˆì¸¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                sagemaker_result = invoke_sagemaker_endpoint(endpoint_name, payload)

            if sagemaker_result:
                st.success("âœ… ì¶”ë¡  ì„±ê³µ")
                st.session_state['sagemaker_result'] = sagemaker_result
                st.session_state['actual_df_for_mae'] = actual_df_for_mae
                st.session_state['model_input_df'] = model_input_df
                st.session_state['horizon'] = horizon
            else:
                st.error("âŒ ì¶”ë¡  ì‹¤íŒ¨. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”
    if 'sagemaker_result' in st.session_state:
        st.write("---")
        st.subheader("ğŸ“Š ì¶”ë¡  ê²°ê³¼ ë¶„ì„")
        
        sagemaker_result = st.session_state['sagemaker_result']
        actual_df_for_mae = st.session_state['actual_df_for_mae']
        model_input_df = st.session_state['model_input_df']
        horizon = st.session_state['horizon']

        try:
            # SageMaker ê²°ê³¼ íŒŒì‹±
            predicted_values = None
            
            if isinstance(sagemaker_result, dict):
                if "predictions" in sagemaker_result:
                    predictions = sagemaker_result["predictions"]
                    if isinstance(predictions, list) and len(predictions) > 0:
                        if isinstance(predictions[0], dict) and "mean" in predictions[0]:
                            predicted_values = predictions[0]["mean"]
                        else:
                            predicted_values = predictions
                elif isinstance(sagemaker_result, list):
                    predicted_values = sagemaker_result
            elif isinstance(sagemaker_result, list):
                predicted_values = sagemaker_result
            
            if predicted_values is None or len(predicted_values) != horizon:
                st.error(f"SageMaker ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨. ì˜ˆì¸¡ê°’ ê°œìˆ˜: {len(predicted_values) if predicted_values else 0}, í•„ìš” ê°œìˆ˜: {horizon}")
                st.json(sagemaker_result)
                st.stop()

            # ì˜ˆì¸¡ê°’ì— ëŒ€í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
            last_input_time = model_input_df[TIME_COLUMN].iloc[-1]
            prediction_timestamps = pd.date_range(start=last_input_time + timedelta(hours=1), periods=horizon, freq='H')

            df_predictions = pd.DataFrame({
                TIME_COLUMN: prediction_timestamps,
                f'predicted_{TARGET_COLUMN}': predicted_values
            })

            # 1. ActivePower ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
            st.write(f"#### 1. {TARGET_COLUMN} ì˜ˆì¸¡ ê²°ê³¼")
            fig_power = go.Figure()
            fig_power.add_trace(go.Scatter(x=df_input_data[TIME_COLUMN], y=df_input_data[TARGET_COLUMN],
                                           mode='lines', name='ì‹¤ì œê°’ (ì „ì²´)', line=dict(color='blue')))
            fig_power.add_trace(go.Scatter(x=df_predictions[TIME_COLUMN], y=df_predictions[f'predicted_{TARGET_COLUMN}'],
                                           mode='lines+markers', name='ì˜ˆì¸¡ê°’', line=dict(color='red')))
            fig_power.add_trace(go.Scatter(x=actual_df_for_mae[TIME_COLUMN], y=actual_df_for_mae[TARGET_COLUMN],
                                           mode='markers', name='ì‹¤ì œê°’ (MAE ë¹„êµ ëŒ€ìƒ)', marker=dict(color='orange', size=8)))
            
            fig_power.update_layout(title=f'{TARGET_COLUMN} ì‹¤ì œê°’ vs. ì˜ˆì¸¡ê°’',
                                    xaxis_title='ì‹œê°„', yaxis_title='ì „ë ¥ ì†Œë¹„ëŸ‰ (kW)')
            st.plotly_chart(fig_power, use_container_width=True)

            # 2. ì „ê¸° ìš”ê¸ˆ ë° íƒ„ì†Œ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ ì‹œê°í™”
            st.write("#### 2. ì˜ˆì¸¡ëœ ì „ê¸° ìš”ê¸ˆ ë° íƒ„ì†Œ ë°°ì¶œëŸ‰")
            df_predictions['predicted_bill (ì›)'] = df_predictions[f'predicted_{TARGET_COLUMN}'] * ELECTRICITY_RATE_KWH
            df_predictions['predicted_carbon (kgCO2)'] = df_predictions[f'predicted_{TARGET_COLUMN}'] * CARBON_COEFFICIENT_KWH

            fig_derived = go.Figure()
            fig_derived.add_trace(go.Scatter(x=df_predictions[TIME_COLUMN], y=df_predictions['predicted_bill (ì›)'],
                                             mode='lines', name='ì˜ˆìƒ ì „ê¸° ìš”ê¸ˆ (ì›)', yaxis="y1"))
            fig_derived.add_trace(go.Scatter(x=df_predictions[TIME_COLUMN], y=df_predictions['predicted_carbon (kgCO2)'],
                                             mode='lines', name='ì˜ˆìƒ íƒ„ì†Œ ë°°ì¶œëŸ‰ (kgCO2)', yaxis="y2"))

            fig_derived.update_layout(
                title='ì‹œê°„ëŒ€ë³„ ì˜ˆìƒ ì „ê¸° ìš”ê¸ˆ ë° íƒ„ì†Œ ë°°ì¶œëŸ‰',
                xaxis_title='ì‹œê°„',
                yaxis=dict(title='ì˜ˆìƒ ì „ê¸° ìš”ê¸ˆ (ì›)', side='left', showgrid=False),
                yaxis2=dict(title='ì˜ˆìƒ íƒ„ì†Œ ë°°ì¶œëŸ‰ (kgCO2)', side='right', overlaying='y', showgrid=False),
                legend=dict(x=0.1, y=1.1, orientation="h")
            )
            st.plotly_chart(fig_derived, use_container_width=True)
            
            st.dataframe(df_predictions[[TIME_COLUMN, f'predicted_{TARGET_COLUMN}', 'predicted_bill (ì›)', 'predicted_carbon (kgCO2)']])

            # 3. MAE ì •í™•ë„ ìˆ˜ì¹˜í™” / ì‹œê°í™”
            st.write("#### 3. ëª¨ë¸ ì •í™•ë„ (MAE)")
            comparison_df = pd.merge(actual_df_for_mae[[TIME_COLUMN, TARGET_COLUMN]],
                                     df_predictions[[TIME_COLUMN, f'predicted_{TARGET_COLUMN}']],
                                     on=TIME_COLUMN, how='inner')
            
            if comparison_df.empty or len(comparison_df) != horizon:
                st.warning(f"MAEë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì˜ ë§¤ì¹­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ë§¤ì¹­ëœ í–‰: {len(comparison_df)}, Horizon: {horizon})")
            else:
                mae = np.mean(np.abs(comparison_df[TARGET_COLUMN] - comparison_df[f'predicted_{TARGET_COLUMN}']))
                st.metric(label=f"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE) for {TARGET_COLUMN}", value=f"{mae:.4f}")

                # MAE ì‹œê°í™” (ê²Œì´ì§€ ì°¨íŠ¸)
                max_mae_gauge = max(mae * 2, np.mean(actual_df_for_mae[TARGET_COLUMN]) * 0.5) if mae > 0 else 1

                fig_mae_gauge = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=mae,
                    title={'text': f"MAE ({TARGET_COLUMN}) - ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ"},
                    gauge={
                        'axis': {'range': [0, max_mae_gauge]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, max_mae_gauge * 0.25], 'color': "lightgreen"},
                            {'range': [max_mae_gauge * 0.25, max_mae_gauge * 0.5], 'color': "yellow"},
                            {'range': [max_mae_gauge * 0.5, max_mae_gauge], 'color': "lightcoral"}
                        ],
                    }
                ))
                fig_mae_gauge.update_layout(height=300)
                st.plotly_chart(fig_mae_gauge, use_container_width=True)
                
                # ì˜¤ì°¨ ì‹œê°í™” (ì‹¤ì œ vs ì˜ˆì¸¡)
                fig_error = go.Figure()
                fig_error.add_trace(go.Scatter(x=comparison_df[TIME_COLUMN], y=comparison_df[TARGET_COLUMN], 
                                              mode='lines+markers', name='ì‹¤ì œê°’'))
                fig_error.add_trace(go.Scatter(x=comparison_df[TIME_COLUMN], y=comparison_df[f'predicted_{TARGET_COLUMN}'], 
                                              mode='lines+markers', name='ì˜ˆì¸¡ê°’'))
                fig_error.update_layout(title='MAE ë¹„êµ: ì‹¤ì œê°’ vs. ì˜ˆì¸¡ê°’ (ì˜ˆì¸¡ ê¸°ê°„)', 
                                       xaxis_title='ì‹œê°„', yaxis_title=TARGET_COLUMN)
                st.plotly_chart(fig_error, use_container_width=True)

        except Exception as e:
            st.error(f"ê²°ê³¼ ì²˜ë¦¬ ë˜ëŠ” ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.write("SageMaker ì‘ë‹µ ë°ì´í„°:")
            st.json(sagemaker_result)
